{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98e89199",
   "metadata": {},
   "source": [
    "Un cop es tenen els grafs amb la forma que es desitja i en format PyTorch, es pot començar a dissenyar i entrenar la xarxa neuronal que donarà una solució al problema.\n",
    "\n",
    "Els grafs (en format .pt) es troben a les carpetes \"train_tsp_pt\" i \"test_tsp_pt\", per a l'entrenament i per al test corresponentment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd98b6d",
   "metadata": {},
   "source": [
    "# Importacions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dd0fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from pathlib import Path\n",
    "\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, GATv2Conv, LayerNorm\n",
    "from torch_geometric.utils import to_dense_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a7dcc7",
   "metadata": {},
   "source": [
    "# Càrrega de fitxers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fff33956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3464/4247743316.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  graphs_train = [torch.load(f) for f in sorted(train_path.glob(\"*.pt\"))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de grafs de train: 1514\n"
     ]
    }
   ],
   "source": [
    "train_path = Path(\"Datasets/train_pt\")\n",
    "graphs_train = [torch.load(f) for f in sorted(train_path.glob(\"*.pt\"))]\n",
    "print(f\"Nombre de grafs de train: {len(graphs_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85649460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[27, 2], edge_index=[2, 351], edge_attr=[351, 1], y=26, id=[27])\n",
      "tensor([[1., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor(26)\n"
     ]
    }
   ],
   "source": [
    "# Exemples\n",
    "data = graphs_train[300]\n",
    "print(data)\n",
    "print(data.x)\n",
    "print(data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "892da240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalitzar valors arestes\n",
    "#for g in graphs_train + graphs_test:\n",
    "#    mean, std = g.edge_attr.mean(), g.edge_attr.std()\n",
    "#    g.edge_attr = (g.edge_attr - mean) / (std + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94814a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSPGraphDataset(Dataset):\n",
    "    def __init__(self, graphs):\n",
    "        self.graphs = graphs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx]\n",
    "\n",
    "train_dataset = TSPGraphDataset(graphs_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b26ddc",
   "metadata": {},
   "source": [
    "# Disseny GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a95a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSPGNN(nn.Module):\n",
    "    def __init__(self, in_channels=2, hidden_channels=64, heads=4, num_layers=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_proj = nn.Linear(in_channels, hidden_channels * heads)\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "\n",
    "        # First layer\n",
    "        self.layers.append(GATv2Conv(hidden_channels * heads, hidden_channels, heads=heads, edge_dim=1))\n",
    "        self.norms.append(LayerNorm(hidden_channels * heads))\n",
    "\n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.layers.append(GATv2Conv(hidden_channels * heads, hidden_channels, heads=heads, edge_dim=1))\n",
    "            self.norms.append(LayerNorm(hidden_channels * heads))\n",
    "\n",
    "        # Output per node (score per node)\n",
    "        self.out = nn.Linear(hidden_channels * heads, 1)\n",
    "\n",
    "    def forward(self, data, return_probs=False):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        edge_attr = edge_attr.view(-1, 1)  # assegura la forma correcta\n",
    "\n",
    "        # Map input a hidden\n",
    "        x = self.input_proj(x)\n",
    "\n",
    "        # Residual connections\n",
    "        for conv, norm in zip(self.layers, self.norms):\n",
    "            h = conv(x, edge_index, edge_attr)\n",
    "            h = norm(h)\n",
    "            h = F.relu(h)\n",
    "            x = x + h  # residual safe, dimensions coincideixen\n",
    "\n",
    "        logits = self.out(x).squeeze(-1)  # [num_nodes_total]\n",
    "\n",
    "        if return_probs:\n",
    "            # Probabilitats per node dins cada graf\n",
    "            x_dense, mask = to_dense_batch(logits.unsqueeze(-1), batch=data.batch)\n",
    "            probs = torch.softmax(x_dense, dim=1)  # softmax per nodes dins el graf\n",
    "            return probs, mask\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4e31f7",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2036c97a",
   "metadata": {},
   "source": [
    "## Configuració"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6928e720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURACIÓ ---\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = TSPGNN(\n",
    "    in_channels=2,\n",
    "    hidden_channels=32,\n",
    "    heads=4,\n",
    "    num_layers=2\n",
    ").to(device)\n",
    "\n",
    "# Optimitzador amb regularització\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.001,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "# Scheduler \n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=20,\n",
    "    gamma=0.5\n",
    ")\n",
    "\n",
    "# Classificació per node, y = target_idx (enter)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340659b9",
   "metadata": {},
   "source": [
    "## Funcions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d899ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion, device, scheduler=None):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # logits per node\n",
    "        logits = model(data)  # [num_nodes_total]\n",
    "\n",
    "        # Transformem a batch dens per graf\n",
    "        logits_dense, mask = to_dense_batch(logits.unsqueeze(-1), batch=data.batch)\n",
    "        # logits_dense: [batch_size, max_num_nodes, 1]\n",
    "        # mask: [batch_size, max_num_nodes] → True per nodes reals\n",
    "\n",
    "        batch_loss = 0.0\n",
    "        batch_size = logits_dense.size(0)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            num_nodes_i = mask[i].sum()\n",
    "            logits_i = logits_dense[i, :num_nodes_i, 0]  # nodes reals\n",
    "            target_i = data.y[i]  # enter que indica el target dins del graf\n",
    "            batch_loss += criterion(logits_i.unsqueeze(0), target_i.unsqueeze(0))\n",
    "\n",
    "        batch_loss /= batch_size\n",
    "        batch_loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 2.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        total_loss += batch_loss.item()\n",
    "\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ceaaf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_correct_top1 = 0\n",
    "    total_graphs = 0\n",
    "    normalized_ranks = []\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        # logits dens per graf i softmax per node\n",
    "        probs_dense, mask = model(data, return_probs=True)\n",
    "        batch_size, max_nodes, _ = probs_dense.size()\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            num_nodes_i = mask[i].sum()\n",
    "            probs_i = probs_dense[i, :num_nodes_i, 0]  # nodes reals\n",
    "            target_i = data.y[i]\n",
    "\n",
    "            # --- Top1 Accuracy ---\n",
    "            pred_idx = probs_i.argmax()\n",
    "            if pred_idx == target_i:\n",
    "                total_correct_top1 += 1\n",
    "            total_graphs += 1\n",
    "\n",
    "            # --- Normalized Rank ---\n",
    "            sorted_indices = torch.argsort(probs_i, descending=True)\n",
    "            rank = (sorted_indices == target_i).nonzero(as_tuple=True)[0].item() + 1\n",
    "            normalized_rank = (rank - 1) / (num_nodes_i - 1)\n",
    "            normalized_ranks.append(normalized_rank)\n",
    "\n",
    "    top1_acc = total_correct_top1 / total_graphs\n",
    "    mean_normalized_rank = sum(normalized_ranks) / len(normalized_ranks)\n",
    "\n",
    "    return top1_acc, mean_normalized_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea40ca4",
   "metadata": {},
   "source": [
    "## Entrenament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b249e154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Loss: 3.245 | Top1Acc: 0.342 | MeanRank: 0.234\n",
      "Epoch 02 | Loss: 2.940 | Top1Acc: 0.355 | MeanRank: 0.211\n",
      "Epoch 03 | Loss: 2.907 | Top1Acc: 0.362 | MeanRank: 0.199\n",
      "Epoch 04 | Loss: 2.881 | Top1Acc: 0.365 | MeanRank: 0.199\n",
      "Epoch 05 | Loss: 2.898 | Top1Acc: 0.365 | MeanRank: 0.199\n",
      "Epoch 06 | Loss: 2.908 | Top1Acc: 0.365 | MeanRank: 0.199\n",
      "Epoch 07 | Loss: 2.896 | Top1Acc: 0.365 | MeanRank: 0.198\n",
      "Epoch 08 | Loss: 2.896 | Top1Acc: 0.364 | MeanRank: 0.199\n",
      "Epoch 09 | Loss: 2.882 | Top1Acc: 0.363 | MeanRank: 0.198\n",
      "Epoch 10 | Loss: 2.903 | Top1Acc: 0.363 | MeanRank: 0.198\n"
     ]
    }
   ],
   "source": [
    "# --- ENTRENAMENT ---\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    loss = train(model, train_loader, optimizer, criterion, device, scheduler=scheduler)\n",
    "    top1_acc, mean_rank = evaluate(model, train_loader, device)\n",
    "    print(f\"Epoch {epoch:02d} | Loss: {loss:.3f} | Top1Acc: {top1_acc:.3f} | MeanRank: {mean_rank:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4eb0863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model guardat a model_gnn2.pt\n"
     ]
    }
   ],
   "source": [
    "# --- GUARDAR MODEL ---\n",
    "save_path = \"model_gnn2.pt\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model guardat a {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65918a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu121\n",
      "12.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
