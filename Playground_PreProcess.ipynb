{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78b976e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import tarfile\n",
    "import gzip\n",
    "\n",
    "import tsplib95\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5da5705",
   "metadata": {},
   "source": [
    "# Funcions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24b97adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tsp_archive(tar_path: Path, extract_path: Path):\n",
    "    \"\"\"\n",
    "    Extract a TSPLIB .tar archive and decompress any .gz files inside it.\n",
    "    Returns a list of .tsp file paths.\n",
    "    \"\"\"\n",
    "\n",
    "    if not tar_path.exists():\n",
    "        raise FileNotFoundError(f\"Archive not found: {tar_path}\")\n",
    "\n",
    "    if extract_path.exists():\n",
    "        shutil.rmtree(extract_path)\n",
    "    extract_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with tarfile.open(tar_path, \"r\") as tar:\n",
    "        tar.extractall(path=extract_path)\n",
    "\n",
    "    for gz_file in extract_path.glob(\"*.gz\"):\n",
    "        output_file = extract_path / gz_file.stem\n",
    "        with gzip.open(gz_file, \"rb\") as f_in, open(output_file, \"wb\") as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "        gz_file.unlink()\n",
    "\n",
    "    print(\"Archive extracted and .gz files decompressed.\")\n",
    "\n",
    "    return sorted(extract_path.glob(\"*.tsp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c99ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_graph(G):\n",
    "    \"\"\"\n",
    "    Prepare a TSPLIB graph loaded with tsplib95:\n",
    "    - ensure undirected\n",
    "    - remove self-loops\n",
    "    - keep only edge weight\n",
    "    - keep only node id + initial/current/target\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure undirected structure\n",
    "    G = nx.Graph(G)\n",
    "\n",
    "    # Remove self-loops\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "    # Initialize node attributes\n",
    "    first_node = min(G.nodes)\n",
    "    for node in G.nodes:\n",
    "        G.nodes[node].clear()\n",
    "        G.nodes[node][\"initial\"] = int(node == first_node)\n",
    "        G.nodes[node][\"current\"] = int(node == first_node)\n",
    "        G.nodes[node][\"target\"] = 0\n",
    "\n",
    "    # Keep only edge weight\n",
    "    for u, v, attrs in G.edges(data=True):\n",
    "        w = attrs.get(\"weight\", None)\n",
    "        attrs.clear()\n",
    "        attrs[\"weight\"] = w\n",
    "\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e11bb202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_graph(G):\n",
    "    \"\"\"\n",
    "    Prepare a TSPLIB graph loaded with tsplib95:\n",
    "    - ensure undirected\n",
    "    - remove self-loops\n",
    "    - convert to 1-based indexing if needed\n",
    "    - keep only edge weight\n",
    "    - initialize node attributes (initial/current/target)\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure undirected structure\n",
    "    G = nx.Graph(G)\n",
    "\n",
    "    # Remove self-loops\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "    # --- NEW: Detect and convert 0-based graphs to 1-based ---\n",
    "    nodes = sorted(G.nodes())\n",
    "    if nodes[0] == 0:\n",
    "        # Build mapping: 0→1, 1→2, ..., n-1→n\n",
    "        mapping = {old: old + 1 for old in nodes}\n",
    "        G = nx.relabel_nodes(G, mapping, copy=True)\n",
    "\n",
    "    # Initialize node attributes\n",
    "    first_node = min(G.nodes)\n",
    "    for node in G.nodes:\n",
    "        G.nodes[node].clear()\n",
    "        G.nodes[node][\"initial\"] = int(node == first_node)\n",
    "        G.nodes[node][\"current\"] = int(node == first_node)\n",
    "        G.nodes[node][\"target\"] = 0\n",
    "\n",
    "    # Keep only edge weight\n",
    "    for u, v, attrs in G.edges(data=True):\n",
    "        w = attrs.get(\"weight\", None)\n",
    "        attrs.clear()\n",
    "        attrs[\"weight\"] = w\n",
    "\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e6532c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_to_pyg(G):\n",
    "    \"\"\"\n",
    "    Convert a prepared NetworkX TSP graph into a PyTorch Geometric Data object.\n",
    "    Keeps:\n",
    "      - x: [initial, current]\n",
    "      - edge_index (bidirectional)\n",
    "      - edge_attr (weight)\n",
    "      - node_id (original TSPLIB ids)\n",
    "      - y: index of target node (0-based)\n",
    "    \"\"\"\n",
    "\n",
    "    # Sorted node list for consistent indexing\n",
    "    nodes = sorted(G.nodes())\n",
    "    mapping = {node: i for i, node in enumerate(nodes)}\n",
    "\n",
    "    # Node features\n",
    "    x = torch.tensor(\n",
    "        [\n",
    "            [\n",
    "                G.nodes[node][\"initial\"],\n",
    "                G.nodes[node][\"current\"]\n",
    "            ]\n",
    "            for node in nodes\n",
    "        ],\n",
    "        dtype=torch.float\n",
    "    )\n",
    "\n",
    "    # Original TSPLIB node IDs\n",
    "    node_id = torch.tensor(nodes, dtype=torch.long)\n",
    "\n",
    "    # Target node (converted to PyTorch index)\n",
    "    target_node = next((node for node in nodes if G.nodes[node][\"target\"] == 1), None)\n",
    "    y = torch.tensor(\n",
    "        mapping[target_node] if target_node is not None else -1,\n",
    "        dtype=torch.long\n",
    "    )\n",
    "\n",
    "    # Edges (bidirectional)\n",
    "    edge_index_list = []\n",
    "    edge_attr_list = []\n",
    "\n",
    "    for u, v, attrs in G.edges(data=True):\n",
    "        i, j = mapping[u], mapping[v]\n",
    "        w = attrs[\"weight\"]\n",
    "\n",
    "        edge_index_list.append([i, j])\n",
    "        edge_attr_list.append([w])\n",
    "\n",
    "        edge_index_list.append([j, i])\n",
    "        edge_attr_list.append([w])\n",
    "\n",
    "    edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_attr_list, dtype=torch.float)\n",
    "\n",
    "    # Build Data object\n",
    "    return Data(\n",
    "        x=x,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "        node_id=node_id,\n",
    "        y=y\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "498cb3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_graphs(G, tour):\n",
    "    \"\"\"\n",
    "    Given a prepared graph G and a normalized tour,\n",
    "    generate one graph per decision (num_nodes - 2).\n",
    "    \"\"\"\n",
    "\n",
    "    graphs = []\n",
    "\n",
    "    # Copy nodes to track which remain\n",
    "    remaining = list(tour)\n",
    "\n",
    "    initial = tour[0]\n",
    "\n",
    "    for step in range(len(tour) - 2):\n",
    "        current = tour[step]\n",
    "        target = tour[step + 1]\n",
    "\n",
    "        # Build a fresh copy of the graph\n",
    "        H = G.copy()\n",
    "\n",
    "        # Remove visited nodes except initial and current\n",
    "        visited = tour[:step]\n",
    "        for v in visited:\n",
    "            if v != initial:\n",
    "                if v in H:\n",
    "                    H.remove_node(v)\n",
    "\n",
    "        # Reset attributes\n",
    "        for node in H.nodes:\n",
    "            H.nodes[node][\"initial\"] = int(node == initial)\n",
    "            H.nodes[node][\"current\"] = int(node == current)\n",
    "            H.nodes[node][\"target\"] = int(node == target)\n",
    "\n",
    "        graphs.append(H)\n",
    "\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4cdd3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_opt_tour(tour_path: Path):\n",
    "    \"\"\"\n",
    "    Load a TSPLIB .opt.tour file and return the tour as a list of node IDs.\n",
    "    Handles:\n",
    "      - one node per line\n",
    "      - multiple nodes per line\n",
    "      - -1 or EOF termination\n",
    "    \"\"\"\n",
    "    tour = []\n",
    "    reading = False\n",
    "\n",
    "    with open(tour_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "\n",
    "            if line == \"TOUR_SECTION\":\n",
    "                reading = True\n",
    "                continue\n",
    "\n",
    "            if not reading:\n",
    "                continue\n",
    "\n",
    "            if line == \"-1\" or line == \"EOF\":\n",
    "                break\n",
    "\n",
    "            # Split line into tokens (handles multiple numbers per line)\n",
    "            parts = line.split()\n",
    "            for p in parts:\n",
    "                tour.append(int(p))\n",
    "\n",
    "    # Remove possible duplicated last node\n",
    "    if len(tour) > 1 and tour[0] == tour[-1]:\n",
    "        tour = tour[:-1]\n",
    "\n",
    "    return tour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03dc87bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_graph(data: Data, pt_path: Path, count: int):\n",
    "    \"\"\"\n",
    "    Save a PyTorch Geometric Data object to disk with a sequential filename.\n",
    "    \"\"\"\n",
    "    file_path = pt_path / f\"{count:05d}.pt\"\n",
    "    torch.save(data, file_path)\n",
    "    return count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db47b29",
   "metadata": {},
   "source": [
    "# PLAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33b4e70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive extracted and .gz files decompressed.\n"
     ]
    }
   ],
   "source": [
    "# Prepare output directory\n",
    "pt_path = Path(\"Datasets/train_pyg\")\n",
    "if pt_path.exists():\n",
    "    shutil.rmtree(pt_path)\n",
    "pt_path.mkdir(parents=True)\n",
    "\n",
    "count = 0\n",
    "\n",
    "# Extract archive\n",
    "tar_path = Path(\"Datasets/ALL_tsp.tar\")\n",
    "extract_path = Path(\"Datasets/ALL_tsp\")\n",
    "tsp_files = extract_tsp_archive(tar_path, extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9047cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSP: brg180\n",
      "Tour length: 180 [1, 12, 11, 10, 9, 8, 162, 163, 164, 165, 166, 167, 168, 157, 158, 159, 160, 161, 129, 128, 127, 126, 125, 124, 123, 122, 121, 132, 131, 130, 49, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 109, 37, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 99, 98, 97, 108, 107, 106, 105, 104, 103, 102, 101, 100, 145, 156, 155, 154, 153, 152, 151, 150, 149, 148, 147, 146, 64, 65, 66, 67, 68, 69, 70, 71, 72, 61, 62, 63, 29, 28, 27, 26, 25, 36, 35, 34, 33, 32, 31, 30, 133, 144, 143, 142, 141, 140, 139, 138, 137, 136, 135, 134, 89, 88, 87, 86, 85, 96, 95, 94, 93, 92, 91, 90, 17, 16, 15, 14, 13, 24, 23, 22, 21, 20, 19, 18, 75, 74, 73, 84, 83, 82, 81, 80, 79, 78, 77, 76, 179, 178, 177, 176, 175, 174, 173, 172, 171, 170, 169, 180, 7, 6, 5, 4, 3, 2]\n",
      "Nodes in G: 180 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180]\n"
     ]
    }
   ],
   "source": [
    "tsp_file = tsp_files[10]\n",
    "name = tsp_file.stem\n",
    "tour_path = extract_path / f\"{name}.opt.tour\"\n",
    "\n",
    "problem = tsplib95.load(tsp_file)\n",
    "G = prepare_graph(problem.get_graph())\n",
    "tour = load_opt_tour(tour_path)\n",
    "\n",
    "print(\"TSP:\", name)\n",
    "print(\"Tour length:\", len(tour), tour)\n",
    "print(\"Nodes in G:\", len(G.nodes), G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee4d24e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a280: tour [1, 280] vs graph [1, 280]\n",
      "att48: tour [1, 48] vs graph [1, 48]\n",
      "bayg29: tour [1, 29] vs graph [1, 29]\n",
      "bays29: tour [1, 29] vs graph [1, 29]\n",
      "berlin52: tour [1, 52] vs graph [1, 52]\n",
      "brg180: tour [1, 180] vs graph [0, 179]\n",
      "ch130: tour [1, 130] vs graph [1, 130]\n",
      "ch150: tour [1, 150] vs graph [1, 150]\n",
      "eil101: tour [1, 101] vs graph [1, 101]\n",
      "eil51: tour [1, 51] vs graph [1, 51]\n",
      "eil76: tour [1, 76] vs graph [1, 76]\n",
      "fri26: tour [1, 26] vs graph [0, 25]\n",
      "gr120: tour [1, 120] vs graph [1, 120]\n",
      "gr202: tour [1, 202] vs graph [1, 202]\n",
      "gr24: tour [1, 24] vs graph [0, 23]\n",
      "gr48: tour [1, 48] vs graph [0, 47]\n",
      "gr666: tour [1, 666] vs graph [1, 666]\n",
      "gr96: tour [1, 96] vs graph [1, 96]\n",
      "kroA100: tour [1, 100] vs graph [1, 100]\n",
      "kroC100: tour [1, 100] vs graph [1, 100]\n",
      "kroD100: tour [1, 100] vs graph [1, 100]\n",
      "lin105: tour [1, 105] vs graph [1, 105]\n",
      "pa561: tour [1, 561] vs graph [1, 561]\n",
      "pcb442: tour [1, 442] vs graph [1, 442]\n",
      "pr1002: tour [1, 1002] vs graph [1, 1002]\n",
      "pr2392: tour [1, 2392] vs graph [1, 2392]\n",
      "pr76: tour [1, 76] vs graph [1, 76]\n",
      "rd100: tour [1, 100] vs graph [1, 100]\n",
      "st70: tour [1, 70] vs graph [1, 70]\n",
      "tsp225: tour [1, 225] vs graph [1, 225]\n",
      "ulysses16: tour [1, 16] vs graph [1, 16]\n",
      "ulysses22: tour [1, 22] vs graph [1, 22]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import tsplib95\n",
    "\n",
    "root = Path(\"Datasets/ALL_tsp\")\n",
    "\n",
    "for tsp_file in sorted(root.glob(\"*.tsp\")):\n",
    "    name = tsp_file.stem\n",
    "    tour_path = root / f\"{name}.opt.tour\"\n",
    "    if not tour_path.exists():\n",
    "        continue\n",
    "\n",
    "    # Load graph and tour\n",
    "    problem = tsplib95.load(tsp_file)\n",
    "    G = problem.get_graph()\n",
    "    nodes = sorted(G.nodes())  # these are 0-based\n",
    "    tour = []\n",
    "\n",
    "    with open(tour_path, \"r\") as f:\n",
    "        reading = False\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == \"TOUR_SECTION\":\n",
    "                reading = True\n",
    "                continue\n",
    "            if not reading:\n",
    "                continue\n",
    "            if line in (\"-1\", \"EOF\"):\n",
    "                break\n",
    "            for p in line.split():\n",
    "                tour.append(int(p))\n",
    "\n",
    "    # Check indexing\n",
    "    min_tour = min(tour)\n",
    "    max_tour = max(tour)\n",
    "    min_graph = min(nodes)\n",
    "    max_graph = max(nodes)\n",
    "\n",
    "    print(f\"{name}: tour [{min_tour}, {max_tour}] vs graph [{min_graph}, {max_graph}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269293b4",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57e1458",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Main function\n",
    "\"\"\"\n",
    "\n",
    "# Prepare output directory\n",
    "pt_path = Path(\"Datasets/train_pyg\")\n",
    "if pt_path.exists():\n",
    "    shutil.rmtree(pt_path)\n",
    "pt_path.mkdir(parents=True)\n",
    "\n",
    "count = 0\n",
    "\n",
    "# Extract archive\n",
    "tar_path = Path(\"Datasets/ALL_tsp.tar\")\n",
    "extract_path = Path(\"Datasets/ALL_tsp\")\n",
    "tsp_files = extract_tsp_archive(tar_path, extract_path)\n",
    "\n",
    "# Process each TSP instance\n",
    "valid_i = 0\n",
    "for tsp_file in tsp_files:\n",
    "    name = tsp_file.stem\n",
    "    tour_path = extract_path / f\"{name}.opt.tour\"\n",
    "\n",
    "    # Skip if no optimal tour\n",
    "    if not tour_path.exists():\n",
    "        continue\n",
    "\n",
    "    problem = tsplib95.load(tsp_file)\n",
    "    print(f\"\\n---Graph {valid_i}: {problem.name}---\")\n",
    "\n",
    "    # Process only symmetric TSP instances\n",
    "    if problem.type != \"TSP\":\n",
    "        print(f\"⚠️ Skipped (TYPE: {problem.type})\")\n",
    "        continue\n",
    "\n",
    "    # Skip large instances\n",
    "    if problem.dimension > 1000:\n",
    "        print(f\"⚠️ Skipped (DIMENSION: {problem.dimension})\")\n",
    "        continue\n",
    "\n",
    "    # Load graph\n",
    "    print(\"  Loading graph...\")\n",
    "    G = problem.get_graph()\n",
    "\n",
    "    # Clean graph\n",
    "    print(\"  Preparing graph...\")\n",
    "    G = prepare_graph(G)\n",
    "\n",
    "    # Load tour\n",
    "    print(\"  Loading tour...\")\n",
    "    tour = load_opt_tour(tour_path)\n",
    "\n",
    "    # Generate train graphs\n",
    "    print(\"  Generating training graphs...\")\n",
    "    graphs = generate_training_graphs(G, tour)\n",
    "\n",
    "    # Convert to PyTorch Geometric and save Data Object\n",
    "    print(\"  Converting to PyTorch Geometric format and saving...\")\n",
    "    for H in graphs:\n",
    "        data = nx_to_pyg(H)\n",
    "        count = save_graph(data, pt_path, count)\n",
    "\n",
    "    print(\"✅ Success!\")\n",
    "    valid_i += 1\n",
    "\n",
    "print(f\"\\nFinished. Saved {count} graphs to {pt_path}\")\n",
    "shutil.rmtree(extract_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f12bf6",
   "metadata": {},
   "source": [
    "# Outros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "376de63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive extracted and .gz files decompressed.\n"
     ]
    }
   ],
   "source": [
    "tar_path = Path(\"Datasets/ALL_tsp.tar\")\n",
    "extract_path = Path(\"Datasets/ALL_tsp\")\n",
    "tsp_files = extract_tsp_archive(tar_path, extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7a34cb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n"
     ]
    }
   ],
   "source": [
    "problem = tsplib95.load(tsp_files[4])\n",
    "G = problem.get_graph()\n",
    "#print(G.graph)\n",
    "#print(G.__dict__)\n",
    "#print(G.nodes(data=True))\n",
    "#print(G.edges(data=True))\n",
    "\n",
    "G = prepare_graph(G)\n",
    "#print(G.graph)\n",
    "#print(G.__dict__)\n",
    "#print(G.nodes(data=True))\n",
    "#print(G.nodes()[1])\n",
    "#print(G.edges(data=True))\n",
    "#print(G.edges()[1, 2])\n",
    "\n",
    "data = nx_to_pyg(G)\n",
    "#print(data)\n",
    "print(data.x)\n",
    "#print(data.edge_index)\n",
    "#print(data.edge_attr)\n",
    "print(data.node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d178e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_graph(G, title=\"\"):\n",
    "    # Priority: display → coord → spring_layout\n",
    "    if all(\"display\" in G.nodes[n] for n in G.nodes):\n",
    "        pos = {n: G.nodes[n][\"display\"] for n in G.nodes}\n",
    "    elif all(\"coord\" in G.nodes[n] for n in G.nodes):\n",
    "        pos = {n: G.nodes[n][\"coord\"] for n in G.nodes}\n",
    "    else:\n",
    "        pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "    colors = []\n",
    "    for n in G.nodes:\n",
    "        if G.nodes[n][\"initial\"]:\n",
    "            colors.append(\"green\")\n",
    "        elif G.nodes[n][\"current\"]:\n",
    "            colors.append(\"blue\")\n",
    "        elif G.nodes[n][\"target\"]:\n",
    "            colors.append(\"red\")\n",
    "        else:\n",
    "            colors.append(\"lightgray\")\n",
    "\n",
    "    nx.draw(G, pos, with_labels=True, node_color=colors, node_size=600)\n",
    "    plt.title(title)\n",
    "    plt.gca().invert_yaxis()  # TSPLIB coordinates have inverted Y\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b5e728f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bayg29\n",
      "[1, 28, 6, 12, 9, 26, 3, 29, 5, 21, 2, 20, 10, 4, 15, 18, 14, 17, 22, 11, 19, 25, 7, 23, 8, 27, 16, 13, 24]\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n",
      "tensor(27)\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n",
      "tensor(5)\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 20, 21, 22, 23, 24, 25, 26, 27, 29])\n",
      "tensor(11)\n",
      "tensor([ 1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
      "        20, 21, 22, 23, 24, 25, 26, 27, 29])\n",
      "tensor(7)\n",
      "tensor([ 1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20,\n",
      "        21, 22, 23, 24, 25, 26, 27, 29])\n",
      "tensor(23)\n",
      "tensor([ 1,  2,  3,  4,  5,  7,  8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
      "        22, 23, 24, 25, 26, 27, 29])\n",
      "tensor(2)\n",
      "tensor([ 1,  2,  3,  4,  5,  7,  8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
      "        22, 23, 24, 25, 27, 29])\n",
      "tensor(23)\n",
      "tensor([ 1,  2,  4,  5,  7,  8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
      "        23, 24, 25, 27, 29])\n",
      "tensor(3)\n",
      "tensor([ 1,  2,  4,  5,  7,  8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
      "        23, 24, 25, 27])\n",
      "tensor(16)\n",
      "tensor([ 1,  2,  4,  7,  8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,\n",
      "        24, 25, 27])\n",
      "tensor(1)\n",
      "tensor([ 1,  2,  4,  7,  8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24,\n",
      "        25, 27])\n",
      "tensor(14)\n",
      "tensor([ 1,  4,  7,  8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25,\n",
      "        27])\n",
      "tensor(4)\n",
      "tensor([ 1,  4,  7,  8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 27])\n",
      "tensor(1)\n",
      "tensor([ 1,  4,  7,  8, 11, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 27])\n",
      "tensor(7)\n",
      "tensor([ 1,  7,  8, 11, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 27])\n",
      "tensor(9)\n",
      "tensor([ 1,  7,  8, 11, 13, 14, 16, 17, 18, 19, 22, 23, 24, 25, 27])\n",
      "tensor(5)\n",
      "tensor([ 1,  7,  8, 11, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27])\n",
      "tensor(7)\n",
      "tensor([ 1,  7,  8, 11, 13, 16, 17, 19, 22, 23, 24, 25, 27])\n",
      "tensor(8)\n",
      "tensor([ 1,  7,  8, 11, 13, 16, 19, 22, 23, 24, 25, 27])\n",
      "tensor(3)\n",
      "tensor([ 1,  7,  8, 11, 13, 16, 19, 23, 24, 25, 27])\n",
      "tensor(6)\n",
      "tensor([ 1,  7,  8, 13, 16, 19, 23, 24, 25, 27])\n",
      "tensor(8)\n",
      "tensor([ 1,  7,  8, 13, 16, 23, 24, 25, 27])\n",
      "tensor(1)\n",
      "tensor([ 1,  7,  8, 13, 16, 23, 24, 27])\n",
      "tensor(5)\n",
      "tensor([ 1,  8, 13, 16, 23, 24, 27])\n",
      "tensor(1)\n",
      "tensor([ 1,  8, 13, 16, 24, 27])\n",
      "tensor(5)\n",
      "tensor([ 1, 13, 16, 24, 27])\n",
      "tensor(2)\n",
      "tensor([ 1, 13, 16, 24])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "problem = tsplib95.load(tsp_files[4])\n",
    "G = problem.get_graph()\n",
    "G = prepare_graph(G)\n",
    "print(problem.name)\n",
    "\n",
    "name = tsp_files[4].stem\n",
    "tour_path = extract_path / f\"{name}.opt.tour\"\n",
    "tour = load_opt_tour(tour_path)\n",
    "print(tour)\n",
    "\n",
    "graphs = generate_training_graphs(G, tour)\n",
    "pyg_graphs = []\n",
    "\n",
    "for i, g in enumerate(graphs):\n",
    "    #draw_graph(g, title=f\"Graph {i}\")\n",
    "    pyg_graph = nx_to_pyg(g)\n",
    "    print(pyg_graph.node_id)\n",
    "    print(pyg_graph.y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
