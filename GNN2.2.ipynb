{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98e89199",
   "metadata": {},
   "source": [
    "Versió optimitzada de GNN2 amb millores en normalització d'arestes i arquitectura de la xarxa.\n",
    "\n",
    "Millores principals:\n",
    "- Normalització GLOBAL dels pesos d'arestes usant estadístiques de TRAIN únicament\n",
    "- Arquitectura GNN mejorada amb dropout i residual connections\n",
    "- Scheduler learning rate sofisticat (CosineAnnealingWarmRestarts)\n",
    "- Early stopping per evitar overfitting\n",
    "- Validació en train/val split (test set no té labels d'entrenament)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd98b6d",
   "metadata": {},
   "source": [
    "# Importacions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dd0fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GATv2Conv, LayerNorm\n",
    "from torch_geometric.utils import to_dense_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a7dcc7",
   "metadata": {},
   "source": [
    "# Càrrega de fitxers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff33956",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = Path(\"Datasets/train_pt\")\n",
    "graphs_train = [torch.load(f, weights_only=False) for f in sorted(train_path.glob(\"*.pt\"))]\n",
    "\n",
    "print(f\"Nombre de grafs de train: {len(graphs_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85649460",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = graphs_train[300]\n",
    "print(data)\n",
    "print(f\"Node features shape: {data.x.shape}\")\n",
    "print(f\"Edge index shape: {data.edge_index.shape}\")\n",
    "print(f\"Edge attr shape: {data.edge_attr.shape}\")\n",
    "print(f\"Target: {data.y}\")\n",
    "print(f\"\\nEdge weights statistics:\")\n",
    "print(f\"Min: {data.edge_attr.min():.4f}, Max: {data.edge_attr.max():.4f}\")\n",
    "print(f\"Mean: {data.edge_attr.mean():.4f}, Std: {data.edge_attr.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892da240",
   "metadata": {},
   "source": [
    "# Normalització d'arestes\n",
    "\n",
    "**Important**: La normalització es fa amb estadístiques de TRAIN únicament.\n",
    "Això assegura que el model aprèn a generalitzar a arestes de diferents escales de manera uniforme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normalize_edges",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edge_weights = torch.cat([g.edge_attr for g in graphs_train], dim=0)\n",
    "edge_mean = all_edge_weights.mean()\n",
    "edge_std = all_edge_weights.std()\n",
    "\n",
    "print(f\"\\nEdge weight statistics (before normalization):\")\n",
    "print(f\"Min: {all_edge_weights.min():.4f}, Max: {all_edge_weights.max():.4f}\")\n",
    "print(f\"Mean: {edge_mean:.4f}, Std: {edge_std:.4f}\")\n",
    "\n",
    "for g in graphs_train:\n",
    "    g.edge_attr = (g.edge_attr - edge_mean) / (edge_std + 1e-8)\n",
    "\n",
    "all_normalized = torch.cat([g.edge_attr for g in graphs_train], dim=0)\n",
    "print(f\"\\nEdge weight statistics (after normalization):\")\n",
    "print(f\"Min: {all_normalized.min():.4f}, Max: {all_normalized.max():.4f}\")\n",
    "print(f\"Mean: {all_normalized.mean():.4f}, Std: {all_normalized.std():.4f}\")\n",
    "print(f\"\\nExample edge weights after normalization: {graphs_train[300].edge_attr[:5].squeeze()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train_val_split",
   "metadata": {},
   "source": [
    "# Train/Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_val_split_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = 0.15\n",
    "val_size = int(len(graphs_train) * val_ratio)\n",
    "train_size = len(graphs_train) - val_size\n",
    "\n",
    "graphs_val = graphs_train[train_size:]\n",
    "graphs_train = graphs_train[:train_size]\n",
    "\n",
    "print(f\"Train set: {len(graphs_train)} graphs\")\n",
    "print(f\"Val set: {len(graphs_val)} graphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94814a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSPGraphDataset(Dataset):\n",
    "    def __init__(self, graphs):\n",
    "        self.graphs = graphs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx]\n",
    "\n",
    "train_dataset = TSPGraphDataset(graphs_train)\n",
    "val_dataset = TSPGraphDataset(graphs_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b26ddc",
   "metadata": {},
   "source": [
    "# Disseny GNN (Versió Millorada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a95a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedTSPGNN(nn.Module):\n",
    "    def __init__(self, in_channels=2, hidden_channels=64, heads=4, num_layers=4, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.heads = heads\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout\n",
    "\n",
    "        out_channels = hidden_channels // heads if hidden_channels % heads == 0 else hidden_channels\n",
    "        \n",
    "        self.input_proj = nn.Linear(in_channels, hidden_channels)\n",
    "        self.input_bn = nn.BatchNorm1d(hidden_channels)\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        self.dropouts = nn.ModuleList()\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            self.layers.append(GATv2Conv(\n",
    "                hidden_channels, \n",
    "                out_channels, \n",
    "                heads=heads, \n",
    "                edge_dim=1,\n",
    "                concat=True\n",
    "            ))\n",
    "            self.norms.append(LayerNorm(hidden_channels))\n",
    "            self.dropouts.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.out_proj = nn.Linear(hidden_channels, hidden_channels // 2)\n",
    "        self.out = nn.Linear(hidden_channels // 2, 1)\n",
    "\n",
    "    def forward(self, data, return_probs=False):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        edge_attr = edge_attr.view(-1, 1)\n",
    "\n",
    "        x = self.input_proj(x)\n",
    "        x = self.input_bn(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        for i, (conv, norm, dropout) in enumerate(zip(self.layers, self.norms, self.dropouts)):\n",
    "            h = conv(x, edge_index, edge_attr)\n",
    "            h = norm(h)\n",
    "            h = F.relu(h)\n",
    "            h = dropout(h)\n",
    "            \n",
    "            if x.shape == h.shape:\n",
    "                x = x + h\n",
    "            else:\n",
    "                x = h\n",
    "\n",
    "        x = self.out_proj(x)\n",
    "        x = F.relu(x)\n",
    "        logits = self.out(x).squeeze(-1)\n",
    "\n",
    "        if return_probs:\n",
    "            x_dense, mask = to_dense_batch(logits.unsqueeze(-1), batch=data.batch)\n",
    "            probs = torch.softmax(x_dense, dim=1)\n",
    "            return probs, mask\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4e31f7",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2036c97a",
   "metadata": {},
   "source": [
    "## Configuració"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6928e720",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "model = ImprovedTSPGNN(\n",
    "    in_channels=2,\n",
    "    hidden_channels=64,\n",
    "    heads=4,\n",
    "    num_layers=4,\n",
    "    dropout=0.25\n",
    ").to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {num_params:,}\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.001,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0=10,\n",
    "    T_mult=2,\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_val_acc = 0.0\n",
    "patience = 20\n",
    "patience_counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340659b9",
   "metadata": {},
   "source": [
    "## Funcions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d899ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion, device, scheduler=None):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(data)\n",
    "\n",
    "        logits_dense, mask = to_dense_batch(logits.unsqueeze(-1), batch=data.batch)\n",
    "        batch_loss = 0.0\n",
    "        batch_size = logits_dense.size(0)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            num_nodes_i = mask[i].sum()\n",
    "            logits_i = logits_dense[i, :num_nodes_i, 0]\n",
    "            target_i = data.y[i]\n",
    "            batch_loss += criterion(logits_i.unsqueeze(0), target_i.unsqueeze(0))\n",
    "\n",
    "        batch_loss /= batch_size\n",
    "        batch_loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        total_loss += batch_loss.item()\n",
    "\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceaaf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_correct_top1 = 0\n",
    "    total_graphs = 0\n",
    "    normalized_ranks = []\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        probs_dense, mask = model(data, return_probs=True)\n",
    "        batch_size, max_nodes, _ = probs_dense.size()\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            num_nodes_i = mask[i].sum()\n",
    "            probs_i = probs_dense[i, :num_nodes_i, 0]\n",
    "            target_i = data.y[i]\n",
    "\n",
    "            pred_idx = probs_i.argmax()\n",
    "            if pred_idx == target_i:\n",
    "                total_correct_top1 += 1\n",
    "            total_graphs += 1\n",
    "\n",
    "            sorted_indices = torch.argsort(probs_i, descending=True)\n",
    "            rank = (sorted_indices == target_i).nonzero(as_tuple=True)[0].item() + 1\n",
    "            normalized_rank = (rank - 1) / (num_nodes_i - 1) if num_nodes_i > 1 else 0.0\n",
    "            normalized_ranks.append(normalized_rank)\n",
    "\n",
    "    top1_acc = total_correct_top1 / total_graphs if total_graphs > 0 else 0.0\n",
    "    mean_normalized_rank = sum(normalized_ranks) / len(normalized_ranks) if normalized_ranks else 0.0\n",
    "\n",
    "    return top1_acc, mean_normalized_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea40ca4",
   "metadata": {},
   "source": [
    "## Entrenament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b249e154",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "best_val_acc = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "print(f\"\\nEntrenament durant {num_epochs} epochs (amb early stopping si patience={patience}):\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, device, scheduler=scheduler)\n",
    "    train_acc, train_rank = evaluate(model, train_loader, device)\n",
    "    val_acc, val_rank = evaluate(model, val_loader, device)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"model_gnn2_improved_best.pt\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if epoch % 5 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch:3d} | Loss: {train_loss:.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | \"\n",
    "              f\"Train Rank: {train_rank:.4f} | Val Rank: {val_rank:.4f}\")\n",
    "    \n",
    "    if patience_counter >= patience:\n",
    "        print(f\"\\nEarly stopping at epoch {epoch} (no improvement for {patience} epochs)\")\n",
    "        break\n",
    "\n",
    "print(\"-\" * 90)\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save_model",
   "metadata": {},
   "source": [
    "## Guardar model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eb0863",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"model_gnn2_improved_final.pt\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model guardat a {save_path}\")\n",
    "print(f\"Best model guardat a model_gnn2_improved_best.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-javascript",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
